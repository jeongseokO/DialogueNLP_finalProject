{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23ee0d0b84f4167903d67dfa1c99444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\"\"\"\n",
    "# 모델과 토크나이저 로드\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../../../../data/jeongseokoh/hub/tokenizer/models--meta-llama--Llama-2-7b-chat-hf/snapshots/c1b0db933684edbfe29a06fa47eb19cc48025e93/\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"../../../../data/jeongseokoh/hub/model/models--meta-llama--Llama-2-7b-chat-hf/snapshots/c1b0db933684edbfe29a06fa47eb19cc48025e93/\")\n",
    "# 모델과 토크나이저를 동일한 장치로 이동\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_pipe = pipeline(\n",
    "        model=model, \n",
    "        tokenizer=tokenizer,\n",
    "        return_full_text=True,  # langchain expects the full text\n",
    "        task='text-generation',\n",
    "        device=3,\n",
    "        # we pass model parameters here too\n",
    "        do_sample = True,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
    "        max_new_tokens=512,  # mex number of tokens to generate in the output\n",
    "        repetition_penalty=1.1  # without this output begins repeating\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3311"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_correct_prompt_long = \"\"\"<s> [INST] <<SYS>>As a language model, your role is to determine the primary purpose or goal of the user in a given dialogue. This task is known as Dialogue State Tracking. Your specific task is to read the provided dialogue and identify the user's intent. \"Intent\" refers to the main purpose or goal of the user in the dialogue, such as booking a hotel or finding a restaurant. \\n<</SYS>>\n",
    "make a response referring to intent list: [find_hotel,find_restaurant, book_train, find_attraction, find_bus, find_hospital, find_hotel, find_police, find_restaurant, find_taxi, find_train]\n",
    "I'll give you few examples below. \n",
    "\n",
    "\n",
    "#### Example1 Dialogue:\n",
    "<user>We are looking for staying in a place.\n",
    "<user>Yes, we will be in Cambridge.\n",
    "<system>We have 33 locations to stay, do you have any other requirements?<user>We can afford only moderately priced hotels.\n",
    "<user>Yes, we are in the south part of the town.\n",
    "<user>We should also expect free wifi.\n",
    "output: find_hotel,find_restaurant,find_hospital\n",
    "\n",
    "#### Example2 Dialogue:\n",
    "<user>Could you get us a taxi?\n",
    "<user>It's for a bit later.\n",
    "<user>Yes, we need to get there by the late evening.\n",
    "<user>Make sure we arrive by 20:00.\n",
    "output: find_taxi\n",
    "\n",
    "#### Example3 Dialogue:\n",
    "<user>Should we check out the restaurant you mentioned?\n",
    "<user>Yes, let's look for information about restaurant alimentum.\n",
    "output: find_restaurant,find_hospital\n",
    "\n",
    "Task Instructions: Identify the user's intent. Your response should be concise and formatted as the intent only. There is no need for an explanatory response. Simply provide your answer in the following format:\n",
    "output: Your Answer\n",
    "[/INST]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "inform_correct_prompt_long = \"\"\"<s> [INST] <<SYS>>Your task is to analyze each provided dialogue and extract key information such as location, time, price range, and other pertinent details. The critical aspect of this task is to format this information in a specific style, which is \"category:detail\". Review the example dialogues, identify the necessary information, and present it in the designated output format.\\n<</SYS>>\n",
    "category list: [attraction-area, attraction-name, attraction-type, bus-day, bus-departure, bus-destination, bus-leaveat, hospital-department, hotel-area, hotel-bookday, hotel-bookpeople, hotel-bookstay, hotel-internet, hotel-name, hotel-parking, hotel-pricerange, hotel-stars, hotel-type, restaurant-area, restaurant-bookday, restaurant-bookpeople, restaurant-booktime, restaurant-food, restaurant-name, restaurant-pricerange, taxi-arriveby, taxi-departure, taxi-destination, taxi-leaveat, train-arriveby, train-bookpeople, train-day, train-departure, train-destination, train-leaveat]\n",
    "I'll give you an example of scale for each task:\n",
    "<domain>-day:monday,\n",
    "<domain>-departure:12:00,\n",
    "<domain>-arriveby:13:00,\n",
    "<domain>-bookpeople:3,\n",
    "<domain>-pricerange:moderate,\n",
    "<domain>-food: indian,\n",
    "<domain>-leaveat: 11:00,\n",
    "<domain>-name: warkworth house,\n",
    "<domain>-area: west\n",
    "\n",
    "\n",
    "Now I'll give you few dialogue examples below. \n",
    "\n",
    "#### Example1 Dialogue:\n",
    "<user>Can you help me find restaurant information?\n",
    "<user>A restaurant for today please\n",
    "<system>There are many options in Cambridge, do you have any tastes in particular?\n",
    "<user>Let's look for some British food.\n",
    "<user>Yes I like british.\n",
    "<user>What can we find in a British restaurant?\n",
    "output: <<restaurant-food:british>>\n",
    "\n",
    "#### Example2 Dialogue:\n",
    "<user>We want to go to an Indian restaurant.\n",
    "<user>Yes, we'll have so much fun.\n",
    "<user>Oh but there's a specific area we want it in.\n",
    "<user>Oh yes, we want to be in the north.\n",
    "output: <<restaurant-area:north,restaurant-food:indian>>\n",
    "\n",
    "#### Example3 Dialogue:\n",
    "<user>Let's go somewhere to eat.\n",
    "<user>Do you have any place in mind?\n",
    "<user>I know a restaurant known as Sala Thong.\n",
    "<system>Ah yes, I have that right here. It's an expensive Thai restaurant in the west end. How many people would you like to reserve a table for, and what day/time?\n",
    "<user>This is the information we needed.\n",
    "<user>Yes, I think this is enough for us.\n",
    "<system>Are you sure you don't need help with anything else?\n",
    "<user>Is there any swimmingpool there?<user>Where are you looking for the swimming pool?\n",
    "<user>I'm in in the east.\n",
    "<system>Abbey pool and astroturf pitch is in the east. Would you like the address and postal code?\n",
    "<user>This is great and this is what I wanted\n",
    "<user>I think we would be needing the address.\n",
    "<user>Yes, there is no need for the postal code.\n",
    "output: <<restaurant-name:sala thong,attraction-area:east,attraction-type:swimmingpool>>\n",
    "\n",
    "Task Instructions: Respond in the following format like <<restaurant-pricerange:moderate, ..., restaurant-area:west>>, which includes domain and category list mentioned above. identify and format the key information from the overall dialogue. Ensure all outputs strictly adhere to the \"category:detail\" format as illustrated in the examples. It is imperative to maintain this format for consistency in the task. Do not explain your answer. It is short-answer question!\n",
    "Your response should be concise and directly formatted as required.\n",
    "output: <<answer>>\n",
    "[/INST]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "###########리퀘스트는 아직 완성 못했습니다. 프롬프트 짜고 코드도 조금 손봐야합니다. \n",
    "request_correct_prompt_long = \"\"\"<s> [INST] <<SYS>>As a language model, your role is to determine the primary purpose or goal of the user in a given dialogue. This task is known as Dialogue State Tracking. Your specific task is to read the provided dialogue and identify the user's request. \"Request\" refers to the additional information or clarification that the user is asking for, such as availability, additional services, or specific details. \\n<</SYS>>\n",
    "Make a response referring to request list: [attraction-address,attraction-area,attraction-entrance fee,attraction-name,attraction-parking,attraction-phone,attraction-postcode,attraction-type,hospital-address,hospital-name,hospital-phone,hospital-postcode,hotel-address,hotel-area,hotel-internet,hotel-name,hotel-parking,hotel-phone,hotel-postcode,hotel-pricerange,hotel-ref,hotel-stars,hotel-type,police-address,police-department,police-name,police-phone,police-postcode,restaurant-address,restaurant-area,restaurant-food,restaurant-name,restaurant-phone,restaurant-postcode,restaurant-pricerange,restaurant-ref,taxi-name,taxi-phone,taxi-type,train-arriveby,train-duration,train-leaveat,train-name,train-price,train-ref,train-trainid]\n",
    "I'll give you few examples below. \n",
    "\n",
    "<</SYS>>\n",
    "#### Example1 Dialogue:\n",
    "<user>Let's go somewhere to eat. I just want to eat Chinese?\n",
    "<user>I will join you. Can you suggest us some Chinese restaurants that are located in the center of the town?\n",
    "<system>There are 10 Chinese restaurants in the centre of town. Would you like a moderately priced one or an expensive one? We have a few cheap.\n",
    "<user>I don't want to go with a cheap one. What do you save my buddy?\n",
    "<user>I also agree with you on this. I think we should avoid the cheap one.\n",
    "<user>So it is final that we are going ahead with an expensive one.\n",
    "<system>I have found tang Chinese which is here in the centre. Would you like to start a reservation?\n",
    "<user>If it fulfills our criteria, I think we should go ahead with the booking. What do you say on this?\n",
    "<user>I think we should go ahead with the booking. I forgot to tell you that two of my friends are also joining us.\n",
    "<user>So that would make us a total of 4 people. Is Friday fine for you?\n",
    "<user>Yes, Friday is good for us. So, please make a reservation for four people at 16:15 on Friday. Please save the reference number at the earliest.\n",
    "Request: restaurant-ref\n",
    "\n",
    "#### Example2 Dialogue:\n",
    "<user>we are looking for a place to go\n",
    "<user>yes, an attraction in cambridge\n",
    "<user>perhaps an architecture attraction\n",
    "<system>There are 5 architecture attractions in the centre. WIll one of those work?\n",
    "<user>i'm sure one will work\n",
    "<user>what would you suggest?\n",
    "<user>yes, could you please recommend one for us\n",
    "Request: attraction-name\n",
    "\n",
    "#### Example3 Dialogue:\n",
    "<user>We are going to Cambridge.\n",
    "<user>Yes, we want to try the local restaurants there.\n",
    "<user>But we will also need a place to stay.\n",
    "<user>Yes we would need a hotel.\n",
    "<system>There are many restaurants. Can you please elaborate on what you would like?\n",
    "<user>First, we will need a hotel with a particular rating.\n",
    "<user>Yes, we are looking for something 3 stars.\n",
    "<user>We would need internet as well.\n",
    "<user>Yes, so we need to make sure that it has free wifi.\n",
    "<system>I have 5 options for you, located all over town. Do you have a certain area or price range in mind?\n",
    "<user>We would like some cheap price range place with chinese food.\n",
    "<user>Yes, we will be in the west part of the town.\n",
    "<user>We would need an expensive hotel with 3 stars and wifi.\n",
    "<user>Yes, we would need the hotel address, area and postcode as well.\n",
    "Request: hotel-area,hotel-address\n",
    "\n",
    "Task Instructions: Identify the user's request. Your response should be concise and formatted as the request only. Do not explain your answer. It is a short-answer question. There is no need for an explanatory response. Simply provide your answer in the following format:\n",
    "Request: Your Answer\n",
    "\"\"\"\n",
    "len(inform_correct_prompt_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"intent_test_data.json\", \"r\") as file:\n",
    "    test_dataset = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2869/2869 [35:43<00:00,  1.34it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 1956, fp: 797, fn: 356\n",
      "F1: 0.7723593287265548\n",
      "Precision: 0.7104976389393389\n",
      "Recall: 0.8460207612456747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델을 평가하기 위한 함수\n",
    "def evaluate(model, tokenizer, dataset, device='cuda:3'):\n",
    "    y_pred = []\n",
    "    y_real = []\n",
    "    model.to(device)\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    for text in dataset[\"input\"]:\n",
    "        input_data.append(text)\n",
    "    for text in dataset[\"output\"]:\n",
    "        output_data.append(text)\n",
    "    for text in output_data:\n",
    "        out = text.split(\",\")\n",
    "        y_real.append(out)\n",
    "    #print(y_real)\n",
    "    tp, fn, fp = 0, 0, 0\n",
    "    for i in tqdm(range(len(dataset['input']))):\n",
    "        # 입력 프롬프트 생성\n",
    "        input_text = f\"{intent_correct_prompt_long}\\n{input_data[i]}\\n\"              #intent_prompt 앞부분에 concat\n",
    "        generated_answer = gen_pipe(input_text)[0]['generated_text'][1600:]\n",
    "        #print(f'OUTPUT_TEXT: {generated_answer}\\n')\n",
    "\n",
    "\n",
    "        #print(f'output_size: {output_size}')\n",
    "        gen_start_id = generated_answer.find(\"put:\") #### 1570번째 붙이는 이유: llama2는 input을 그대로 뱉고 output을 주더라고요. 앞에 input이 대략 1570자가 있다고 보시면 됩니다.\n",
    "        #print(generated_answer[1377+gen_start_id:])\n",
    "        real_gen = generated_answer[4+gen_start_id:].strip().split(\",\") #strip 사용해야함! ## put: 이 4자라서 4를 더해서 1574입니다. \n",
    "        #print(f'real_gen: {real_gen}')\n",
    "        y_pred.append(real_gen)\n",
    "\n",
    "    #true_positive, false_positive, false_negative 계산    \n",
    "    for i, real in enumerate(y_real):\n",
    "        #print(f'real_y: {real}')\n",
    "        #print(f'pred_y: {y_pred[i]}')\n",
    "        real_cnt = Counter(real) \n",
    "        pred_cnt = Counter(y_pred[i])\n",
    "        common = real_cnt & pred_cnt\n",
    "        tp += len(common.values())\n",
    "        if len(real) > len(y_pred[i]):\n",
    "            gap = len(real) - len(common.values())\n",
    "            fn += gap\n",
    "        elif len(real) < len(y_pred[i]):\n",
    "            gap = len(y_pred[i]) - len(common.values())\n",
    "            fp += gap\n",
    "    print(f'tp: {tp}, fp: {fp}, fn: {fn}')\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision*recall/(precision+recall))\n",
    "\n",
    "    metric = [precision, recall, f1]\n",
    "    return metric\n",
    "\n",
    "# 테스트 데이터셋에 대한 모델 평가\n",
    "accuracy = evaluate(model, tokenizer, test_dataset)\n",
    "print(f'F1: {accuracy[2]}\\nPrecision: {accuracy[0]}\\nRecall: {accuracy[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inform Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"inform_test_data.json\", \"r\") as file:\n",
    "    test_dataset = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:40<00:00,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_y: ['']\n",
      "pred_y: ['hotel-name:warkworth house', 'hotel-price-range:moderate', 'hotel-location:cambridge', 'hotel-distance-from-station:5-minutes']\n",
      "real_y: ['hotel-area:south', 'hotel-internet:yes', 'hotel-pricerange:moderate']\n",
      "pred_y: ['hotel-pricerange:moderate', 'hotel-area:south', 'hotel-wifi:yes']\n",
      "real_y: ['hotel-area:south', 'hotel-internet:yes', 'hotel-pricerange:moderate']\n",
      "pred_y: ['hotel-name:bridge guest house', 'hotel-pricerange:moderate', 'hotel-area:south', 'hotel-wifi:yes']\n",
      "real_y: ['restaurant-area:south', 'restaurant-food:chinese', 'hotel-area:south', 'hotel-internet:yes', 'hotel-pricerange:moderate']\n",
      "pred_y: ['hotel-name:bridge guest house', 'hotel-pricerange:moderate', 'hotel-area:south', 'hotel-parking:yes', 'attraction-name:chinese restaurant', 'attraction-area:near hotel']\n",
      "real_y: ['restaurant-name:restaurant alimentum']\n",
      "pred_y: ['restaurant-name:alimentum', 'attraction-distance:2mi', 'attraction-area:citycenter', 'attraction-type:italianrestaurant', 'diningtime:7pm', 'price-range:moderate']\n",
      "real_y: ['restaurant-name:restaurant alimentum']\n",
      "pred_y: ['restaurant-name:alimentum', 'attraction-area:south', 'attraction-type:restaurant', 'attraction-price-range:moderate', 'attraction-phone-number:01223413000', 'attraction-address:cb28pb 152 - 154 Hills Road']\n",
      "real_y: ['taxi-arriveby:20:00']\n",
      "pred_y: ['taxi-arriveby:19:30', 'taxi-destination:west', 'taxi-leaveat:20:00']\n",
      "real_y: ['taxi-arriveby:20:00', 'taxi-departure:clare college']\n",
      "pred_y: ['taxi-arriveby:20:00', 'taxi-departure:clare-college', 'taxi-destination:other-location', 'taxi-pricerange:varies']\n",
      "real_y: ['taxi-arriveby:20:00', 'taxi-departure:clare college', 'taxi-destination:parkside police station']\n",
      "pred_y: ['taxi-departure:clare college', 'taxi-destination:parkside police station', 'taxi-arriveby:20:00']\n",
      "real_y: ['taxi-arriveby:20:00', 'taxi-departure:clare college', 'taxi-destination:parkside police station']\n",
      "pred_y: ['taxi-arriveby:20:00', 'taxi-departure:clare college', 'taxi-destination:parkside police station', 'taxi-leaveat:07:00', 'hotel-bookday:yes', 'hotel-bookpeople:3', 'hotel-bookstay:1night', 'hotel-internet:free', 'hotel-name:the Gonville', 'hotel-parking:free', 'hotel-pricerange:budget', 'hotel-stars:2', 'hotel-type:bedandbreakfast']\n",
      "tp: 13, fp: 38, fn: 0\n",
      "F1: 0.40625\n",
      "Precision: 0.2549019607843137\n",
      "Recall: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델을 평가하기 위한 함수\n",
    "\n",
    "def evaluate(dataset):\n",
    "    y_pred = []\n",
    "    y_real = []\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    for text in dataset[\"input\"][:10]:\n",
    "        input_data.append(text)\n",
    "    for text in dataset[\"output\"][:10]:\n",
    "        output_data.append(text)\n",
    "    for text in output_data:\n",
    "        out = text.split(\",\")\n",
    "        y_real.append(out)\n",
    "    #print(y_real)\n",
    "    tp, fn, fp = 0, 0, 0\n",
    "    for i in tqdm(range(len(dataset['input'][:10]))):\n",
    "        # 입력 프롬프트 생성\n",
    "        input_text = f\"{inform_correct_prompt_long}\\n{input_data[i]}\\n\"              #intent_prompt 앞부분에 concat\n",
    "        generated_answer = gen_pipe(input_text)[0]['generated_text'][3311:]\n",
    "        #print(f'OUTPUT_TEXT: {generated_answer}\\n')\n",
    "\n",
    "\n",
    "        #print(f'output_size: {output_size}')\n",
    "        if \"<<\" in generated_answer:\n",
    "            gen_start_id = generated_answer.find(\"<<\")\n",
    "            gen_end_id = generated_answer.find(\">>\") \n",
    "            #print(generated_answer[gen_start_id:])\n",
    "            real_gen = generated_answer[2+gen_start_id:gen_end_id].strip().split(\",\") \n",
    "            #print(f'real_gen: {real_gen}')\n",
    "        else:\n",
    "            real_gen = \"\"\n",
    "        y_pred.append(real_gen)             \n",
    "        \n",
    "\n",
    "    #true_positive, false_positive, false_negative 계산    \n",
    "    for i, real in enumerate(y_real):\n",
    "        print(f'real_y: {real}')\n",
    "        print(f'pred_y: {y_pred[i]}')\n",
    "        real_cnt = Counter(real) \n",
    "        pred_cnt = Counter(y_pred[i])\n",
    "        common = real_cnt & pred_cnt\n",
    "        tp += len(common.values())\n",
    "        if len(real) > len(y_pred[i]):\n",
    "            gap = len(real) - len(common.values())\n",
    "            fn += gap\n",
    "        elif len(real) < len(y_pred[i]):\n",
    "            gap = len(y_pred[i]) - len(common.values())\n",
    "            fp += gap\n",
    "    print(f'tp: {tp}, fp: {fp}, fn: {fn}')\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision*recall/(precision+recall))\n",
    "\n",
    "    metric = [precision, recall, f1]\n",
    "    return metric\n",
    "\n",
    "# 테스트 데이터셋에 대한 모델 평가\n",
    "accuracy = evaluate(test_dataset)\n",
    "print(f'F1: {accuracy[2]}\\nPrecision: {accuracy[0]}\\nRecall: {accuracy[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"request_test_data.json\", \"r\") as file:\n",
    "    test_dataset = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/home/jeongseokoh/miniconda3/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      " 10%|█         | 2/20 [00:02<00:22,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: hotel-pricerange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:03<00:20,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: hotel-postcode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:05<00:21,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: hotel-name,restaurant-name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:06<00:18,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: restaurant-name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:07<00:17,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: restaurant-name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:10<00:14,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: taxi-name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:11<00:15,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: taxi-name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:13<00:14,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: taxi-name,taxi-phone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:14<00:12,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: restaurant-ref\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:15<00:10,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: restaurant-booking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:16<00:08,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: attraction-address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:18<00:07,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: attraction-name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:19<00:06,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: restaurant-ref\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:20<00:04,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: restaurant-ref\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:21<00:03,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: restaurant-ref\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:24<00:01,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: restaurant-name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:25<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "est: restaurant-food\n",
      "real_y: ['']\n",
      "pred_y: ['']\n",
      "real_y: ['']\n",
      "pred_y: ['hotel-pricerange']\n",
      "real_y: ['hotel-address', 'hotel-parking']\n",
      "pred_y: ['hotel-postcode']\n",
      "real_y: ['']\n",
      "pred_y: ['hotel-name', 'restaurant-name']\n",
      "real_y: ['']\n",
      "pred_y: ['restaurant-name']\n",
      "real_y: ['']\n",
      "pred_y: ['restaurant-name']\n",
      "real_y: ['']\n",
      "pred_y: ['']\n",
      "real_y: ['']\n",
      "pred_y: ['taxi-name']\n",
      "real_y: ['']\n",
      "pred_y: ['taxi-name']\n",
      "real_y: ['']\n",
      "pred_y: ['taxi-name', 'taxi-phone']\n",
      "real_y: ['']\n",
      "pred_y: ['restaurant-ref']\n",
      "real_y: ['']\n",
      "pred_y: ['restaurant-booking']\n",
      "real_y: ['']\n",
      "pred_y: ['attraction-address']\n",
      "real_y: ['']\n",
      "pred_y: ['attraction-name']\n",
      "real_y: ['']\n",
      "pred_y: ['restaurant-ref']\n",
      "real_y: ['']\n",
      "pred_y: ['restaurant-ref']\n",
      "real_y: ['restaurant-ref']\n",
      "pred_y: ['restaurant-ref']\n",
      "real_y: ['']\n",
      "pred_y: ['']\n",
      "real_y: ['']\n",
      "pred_y: ['restaurant-name']\n",
      "real_y: ['']\n",
      "pred_y: ['restaurant-food']\n",
      "tp: 4, fp: 4, fn: 2\n",
      "F1: 0.5714285714285715\n",
      "Precision: 0.5\n",
      "Recall: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델을 평가하기 위한 함수\n",
    "\n",
    "def evaluate(dataset):\n",
    "    y_pred = []\n",
    "    y_real = []\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    for text in dataset[\"input\"]:\n",
    "        input_data.append(text)\n",
    "    for text in dataset[\"output\"]:\n",
    "        output_data.append(text)\n",
    "    for text in output_data:\n",
    "        out = text.split(\",\")\n",
    "        y_real.append(out)\n",
    "    #print(y_real)\n",
    "    tp, fn, fp = 0, 0, 0\n",
    "    for i in tqdm(range(len(dataset['input']))):\n",
    "        # 입력 프롬프트 생성\n",
    "        input_text = f\"{request_correct_prompt_long}\\n{input_data[i]}\\n\"              #intent_prompt 앞부분에 concat\n",
    "        generated_answer = gen_pipe(input_text)[0]['generated_text'][3860:]\n",
    "        #print(f'OUTPUT_TEXT: {generated_answer}\\n')\n",
    "\n",
    "        \n",
    "        #print(f'output_size: {output_size}')\n",
    "        if \"put:\" in generated_answer:\n",
    "            gen_start_id = generated_answer.find(\"put:\")\n",
    "            print(generated_answer[gen_start_id:])\n",
    "            real_gen = generated_answer[4+gen_start_id:].replace(\"*\",\"\").replace(\"\\n\",\"\").strip().split(\",\") \n",
    "            #print(f'real_gen: {real_gen}')\n",
    "        elif \"est:\" in generated_answer:\n",
    "            gen_start_id = generated_answer.find(\"est:\")\n",
    "            #print(generated_answer[gen_start_id:])\n",
    "            real_gen = generated_answer[4+gen_start_id:].replace(\"*\",\"\").replace(\"\\n\",\"\").strip().split(\",\") \n",
    "        else:\n",
    "            real_gen = [\"\"]\n",
    "        y_pred.append(real_gen)             \n",
    "        \n",
    "\n",
    "    #true_positive, false_positive, false_negative 계산    \n",
    "    for i, real in enumerate(y_real):\n",
    "        #print(f'real_y: {real}')\n",
    "        #print(f'pred_y: {y_pred[i]}')\n",
    "        real_cnt = Counter(real) \n",
    "        pred_cnt = Counter(y_pred[i])\n",
    "        common = real_cnt & pred_cnt\n",
    "        tp += len(common.values())\n",
    "        if len(real) > len(y_pred[i]):\n",
    "            gap = len(real) - len(common.values())\n",
    "            fn += gap\n",
    "        elif len(real) < len(y_pred[i]):\n",
    "            gap = len(y_pred[i]) - len(common.values())\n",
    "            fp += gap\n",
    "    print(f'tp: {tp}, fp: {fp}, fn: {fn}')\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision*recall/(precision+recall))\n",
    "\n",
    "    metric = [precision, recall, f1]\n",
    "    return metric\n",
    "\n",
    "# 테스트 데이터셋에 대한 모델 평가\n",
    "accuracy = evaluate(test_dataset)\n",
    "print(f'F1: {accuracy[2]}\\nPrecision: {accuracy[0]}\\nRecall: {accuracy[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env01",
   "language": "python",
   "name": "env01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
