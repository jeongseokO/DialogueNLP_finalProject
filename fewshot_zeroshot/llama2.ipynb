{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "transformers.pipeline(\n",
    "        model=model, tokenizer=tokenizer,\n",
    "        return_full_text=True,  # langchain expects the full text\n",
    "        task='text-generation',\n",
    "        token='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',\n",
    "        # we pass model parameters here too\n",
    "        do_sample = False,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
    "        max_new_tokens=512,  # mex number of tokens to generate in the output\n",
    "        repetition_penalty=1.1  # without this output begins repeating\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load model and tokenizer\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token='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', cache_dir=\"../../../../data/jeongseokoh/hub/tokenizer/\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, token='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', cache_dir=\"../../../../data/jeongseokoh/hub/model/\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt 짜기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "intent_correct_prompt_long = \"\"\"<s> [INST] <<SYS>>As a language model, your role is to determine the primary purpose or goal of the user in a given dialogue. This task is known as Dialogue State Tracking. Your specific task is to read the provided dialogue and identify the user's intent. \"Intent\" refers to the main purpose or goal of the user in the dialogue, such as booking a hotel or finding a restaurant. \\n<</SYS>>\n",
    "make a response referring to intent list: [find_hotel,find_restaurant, book_train, find_attraction, find_bus, find_hospital, find_hotel, find_police, find_restaurant, find_taxi, find_train]\n",
    "I'll give you few examples below. \n",
    "\n",
    "\n",
    "#### Example1 Dialogue:\n",
    "<user>We are looking for staying in a place.\n",
    "<user>Yes, we will be in Cambridge.\n",
    "<system>We have 33 locations to stay, do you have any other requirements?<user>We can afford only moderately priced hotels.\n",
    "<user>Yes, we are in the south part of the town.\n",
    "<user>We should also expect free wifi.\n",
    "output: find_hotel,find_restaurant,find_hospital\n",
    "\n",
    "#### Example2 Dialogue:\n",
    "<user>Could you get us a taxi?\n",
    "<user>It's for a bit later.\n",
    "<user>Yes, we need to get there by the late evening.\n",
    "<user>Make sure we arrive by 20:00.\n",
    "output: find_taxi\n",
    "\n",
    "#### Example3 Dialogue:\n",
    "<user>Should we check out the restaurant you mentioned?\n",
    "<user>Yes, let's look for information about restaurant alimentum.\n",
    "output: find_restaurant,find_hospital\n",
    "\n",
    "Task Instructions: Identify the user's intent. Your response should be concise and formatted as the intent only. There is no need for an explanatory response. Simply provide your answer in the following format:\n",
    "output: Your Answer\n",
    "[/INST]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "inform_correct_prompt_long = \"\"\"<s> [INST] <<SYS>>Your task is to analyze each provided dialogue and extract key information such as location, time, price range, and other pertinent details. The critical aspect of this task is to format this information in a specific style, which is \"category:detail\". Review the example dialogues, identify the necessary information, and present it in the designated output format.\\n<</SYS>>\n",
    "category list: [attraction-area, attraction-name, attraction-type, bus-day, bus-departure, bus-destination, bus-leaveat, hospital-department, hotel-area, hotel-bookday, hotel-bookpeople, hotel-bookstay, hotel-internet, hotel-name, hotel-parking, hotel-pricerange, hotel-stars, hotel-type, restaurant-area, restaurant-bookday, restaurant-bookpeople, restaurant-booktime, restaurant-food, restaurant-name, restaurant-pricerange, taxi-arriveby, taxi-departure, taxi-destination, taxi-leaveat, train-arriveby, train-bookpeople, train-day, train-departure, train-destination, train-leaveat]\n",
    "I'll give you an example of scale for each task:\n",
    "<domain>-day:monday,\n",
    "<domain>-departure:12:00,\n",
    "<domain>-arriveby:13:00,\n",
    "<domain>-bookpeople:3,\n",
    "<domain>-pricerange:moderate,\n",
    "<domain>-food: indian,\n",
    "<domain>-leaveat: 11:00,\n",
    "<domain>-name: warkworth house,\n",
    "<domain>-area: west\n",
    "\n",
    "\n",
    "Now I'll give you few dialogue examples below. \n",
    "\n",
    "#### Example1 Dialogue:\n",
    "<user>Can you help me find restaurant information?\n",
    "<user>A restaurant for today please\n",
    "<system>There are many options in Cambridge, do you have any tastes in particular?\n",
    "<user>Let's look for some British food.\n",
    "<user>Yes I like british.\n",
    "<user>What can we find in a British restaurant?\n",
    "output: <<restaurant-food:british>>\n",
    "\n",
    "#### Example2 Dialogue:\n",
    "<user>We want to go to an Indian restaurant.\n",
    "<user>Yes, we'll have so much fun.\n",
    "<user>Oh but there's a specific area we want it in.\n",
    "<user>Oh yes, we want to be in the north.\n",
    "output: <<restaurant-area:north,restaurant-food:indian>>\n",
    "\n",
    "#### Example3 Dialogue:\n",
    "<user>Let's go somewhere to eat.\n",
    "<user>Do you have any place in mind?\n",
    "<user>I know a restaurant known as Sala Thong.\n",
    "<system>Ah yes, I have that right here. It's an expensive Thai restaurant in the west end. How many people would you like to reserve a table for, and what day/time?\n",
    "<user>This is the information we needed.\n",
    "<user>Yes, I think this is enough for us.\n",
    "<system>Are you sure you don't need help with anything else?\n",
    "<user>Is there any swimmingpool there?<user>Where are you looking for the swimming pool?\n",
    "<user>I'm in in the east.\n",
    "<system>Abbey pool and astroturf pitch is in the east. Would you like the address and postal code?\n",
    "<user>This is great and this is what I wanted\n",
    "<user>I think we would be needing the address.\n",
    "<user>Yes, there is no need for the postal code.\n",
    "output: <<restaurant-name:sala thong,attraction-area:east,attraction-type:swimmingpool>>\n",
    "\n",
    "Task Instructions: Respond in the following format like <<restaurant-pricerange:moderate, ..., restaurant-area:west>>, which includes domain and category list mentioned above. identify and format the key information from the overall dialogue. Ensure all outputs strictly adhere to the \"category:detail\" format as illustrated in the examples. It is imperative to maintain this format for consistency in the task. Your response should be concise and directly formatted as required.\n",
    "output: <<answer>>\n",
    "[/INST]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "###########리퀘스트는 아직 완성 못했습니다. 프롬프트 짜고 코드도 조금 손봐야합니다. \n",
    "request_correct_prompt_long = \"\"\"<s> [INST] <<SYS>>You are a man who detect the main request of the user in the dialogue.\\n<</SYS>>\n",
    "Your task is Tracking a Dialogue State, that  is, Dialogue State Tracking. Read the given dialogue and extract the user's request. The crucial part of this exercise is to format the extracted information in a specific output style, which is \"category-detail\". Request means that Additional information or clarification that the user is asking for, such as availability, additional services, or specific details.\n",
    "request list: [attraction-address,attraction-area,attraction-entrance fee,attraction-name,attraction-parking,attraction-phone,attraction-postcode,attraction-type,hospital-address,hospital-name,hospital-phone,hospital-postcode,hotel-address,hotel-area,hotel-internet,hotel-name,hotel-parking,hotel-phone,hotel-postcode,hotel-pricerange,hotel-ref,hotel-stars,hotel-type,police-address,police-department,police-name,police-phone,police-postcode,restaurant-address,restaurant-area,restaurant-food,restaurant-name,restaurant-phone,restaurant-postcode,restaurant-pricerange,restaurant-ref,taxi-name,taxi-phone,taxi-type,train-arriveby,train-duration,train-leaveat,train-name,train-price,train-ref,train-trainid]\n",
    "I'll give you few examples below. \n",
    "\n",
    "<</SYS>>\n",
    "#### Example1 Dialogue:\n",
    "<user>Let's go somewhere to eat. I just want to eat Chinese?\n",
    "<user>I will join you. Can you suggest us some Chinese restaurants that are located in the center of the town?\n",
    "<system>There are 10 Chinese restaurants in the centre of town. Would you like a moderately priced one or an expensive one? We have a few cheap.\n",
    "<user>I don't want to go with a cheap one. What do you save my buddy?\n",
    "<user>I also agree with you on this. I think we should avoid the cheap one.\n",
    "<user>So it is final that we are going ahead with an expensive one.\n",
    "<system>I have found tang Chinese which is here in the centre. Would you like to start a reservation?\n",
    "<user>If it fulfills our criteria, I think we should go ahead with the booking. What do you say on this?\n",
    "<user>I think we should go ahead with the booking. I forgot to tell you that two of my friends are also joining us.\n",
    "<user>So that would make us a total of 4 people. Is Friday fine for you?\n",
    "<user>Yes, Friday is good for us. So, please make a reservation for four people at 16:15 on Friday. Please save the reference number at the earliest.\n",
    "output: restaurant-ref\n",
    "\n",
    "#### Example2 Dialogue:\n",
    "<user>What kind of food do you want to eat?\n",
    "<user>You know I love alfredo pasta.\n",
    "<user>Okay, so we need a place serving Italian food.\n",
    "<user>Make sure the restaurant is in the city centre.\n",
    "<system>There are nine listings available. What price range were you interested in?\n",
    "<user>I wanted to find a pricey one.\n",
    "<user>Yes, make sure that the restaurant is expensive.\n",
    "<system>Clowns Cafe is a restaurant in the city centre with that price range. Would you like to make a reservation?\n",
    "<user>That sounds like a winner.\n",
    "<user>I think so too.\n",
    "<user>But how close is it from where I am right now?\n",
    "output: \n",
    "\n",
    "#### Example3 Dialogue:\n",
    "<user>We are going to Cambridge.\n",
    "<user>Yes, we want to try the local restaurants there.\n",
    "<user>But we will also need a place to stay.\n",
    "<user>Yes we would need a hotel.\n",
    "<system>There are many restaurants. Can you please elaborate on what you would like?\n",
    "<user>First, we will need a hotel with a particular rating.\n",
    "<user>Yes, we are looking for something 3 stars.\n",
    "<user>We would need internet as well.\n",
    "<user>Yes, so we need to make sure that it has free wifi.\n",
    "<system>I have 5 options for you, located all over town. Do you have a certain area or price range in mind?\n",
    "<user>We would like some cheap price range place with chinese food.\n",
    "<user>Yes, we will be in the west part of the town.\n",
    "<user>We would need an expensive hotel with 3 stars and wifi.\n",
    "<user>Yes, we would need the hotel address, area and postcode as well.\n",
    "output: hotel-area,hotel-address\n",
    "\n",
    "# Your Task: Based on the dialogue below, identify the request. Please say only request list i gave to you. Keep your response concise. Do not repeat! If there is no answer, just don't say anything!\n",
    "Please ensure that all outputs strictly adhere to the following.\n",
    "output: [Your Answer]\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(intent_correct_prompt_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent F1, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import json\n",
    "input_data = []\n",
    "output_data = []\n",
    "with open(\"intent_test_data.json\", \"r\") as file:\n",
    "    test_dataset = json.load(file)\n",
    "for text in test_dataset[\"input\"]:\n",
    "    input_data.append(text)\n",
    "for text in test_dataset[\"output\"]:\n",
    "    output_data.append(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "with open(\"intent_test_data.json\", \"r\") as file:\n",
    "    test_dataset = json.load(file)\n",
    "\n",
    "\n",
    "# 모델을 평가하기 위한 함수\n",
    "def evaluate(model, tokenizer, dataset, device='cuda:3'):\n",
    "    y_pred = []\n",
    "    y_real = []\n",
    "    model.to(device)\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    for text in dataset[\"input\"][:10]:\n",
    "        input_data.append(text)\n",
    "    for text in dataset[\"output\"][:10]:\n",
    "        output_data.append(text)\n",
    "    for text in output_data:\n",
    "        out = text.split(\",\")\n",
    "        y_real.append(out)\n",
    "    #print(y_real)\n",
    "    tp, fn, fp = 0, 0, 0\n",
    "    for i in tqdm(range(len(dataset['input'][:10]))):\n",
    "        # 입력 프롬프트 생성\n",
    "        input_text = f\"{intent_correct_prompt_long}\\n{input_data[i]}\\n\"              #intent_prompt 앞부분에 concat\n",
    "        input_ids = tokenizer.encode(input_text, truncation=True ,max_length=3000, return_tensors='pt').to(device)\n",
    "        #print(f'INPUT_TEXT: {input_text}')\n",
    "        # 모델로부터 답변 생성\n",
    "        output_ids = model.generate(input_ids, max_length=3000)[0]\n",
    "        generated_answer = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "        print(f'OUTPUT_TEXT: {generated_answer[1600:]}\\n')\n",
    "        #print(f'True OUTPUT: {output_data[i]}')\n",
    "        #print(f'True Ans: {output_data[i]}')\n",
    "        #true_positive, false_positive, false_negative 계산\n",
    "\n",
    "        #print(f'output_size: {output_size}')\n",
    "        gen_start_id = generated_answer[1600:].find(\"put:\") #### 1570번째 붙이는 이유: llama2는 input을 그대로 뱉고 output을 주더라고요. 앞에 input이 대략 1570자가 있다고 보시면 됩니다.\n",
    "        #print(generated_answer[1377+gen_start_id:])\n",
    "        real_gen = generated_answer[1604+gen_start_id:].replace(\" \", \"\").split(\",\") #strip 사용해야함! ## put: 이 4자라서 4를 더해서 1574입니다. \n",
    "        print(f'real_gen: {real_gen}')\n",
    "        y_pred.append(real_gen)\n",
    "    for i, real in enumerate(y_real):\n",
    "        #print(f'real_y: {real}')\n",
    "        #print(f'pred_y: {y_pred[i]}')\n",
    "        real_cnt = Counter(real) \n",
    "        pred_cnt = Counter(y_pred[i])\n",
    "        common = real_cnt & pred_cnt\n",
    "        tp += len(common.values())\n",
    "        if len(real) > len(y_pred[i]):\n",
    "            gap = len(real) - len(common.values())\n",
    "            fn += gap\n",
    "        elif len(real) < len(y_pred[i]):\n",
    "            gap = len(y_pred[i]) - len(common.values())\n",
    "            fp += gap\n",
    "        #print(f'tp: {tp}, fp: {fp}, fn: {fn}')\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision*recall/(precision+recall))\n",
    "\n",
    "    metric = [precision, recall, f1]\n",
    "    return metric\n",
    "\n",
    "# 테스트 데이터셋에 대한 모델 평가\n",
    "accuracy = evaluate(model, tokenizer, test_dataset)\n",
    "print(f'F1: {accuracy[2]}\\nPrecision: {accuracy[0]}\\nRecall: {accuracy[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inform F1, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:3\")\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "with open(\"inform_test_data.json\", \"r\") as file:\n",
    "    test_dataset = json.load(file)\n",
    "\n",
    "\n",
    "# 모델을 평가하기 위한 함수\n",
    "def evaluate(model, tokenizer, dataset, device='cuda:3'):\n",
    "    y_pred = []\n",
    "    y_real = []\n",
    "    model.to(device)\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    for text in dataset[\"input\"]:\n",
    "        input_data.append(text)\n",
    "    for text in dataset[\"output\"]:\n",
    "        output_data.append(text)\n",
    "    for text in output_data:\n",
    "        out = text.replace(\" \", \"\").split(\",\")\n",
    "        y_real.append(out)\n",
    "    #print(y_real)\n",
    "    tp, fn, fp = 0, 0, 0\n",
    "    for i in tqdm(range(len(dataset['input']))):\n",
    "        # 입력 프롬프트 생성\n",
    "        input_text = f\"{inform_correct_prompt_long}\\n{input_data[i]}\\n\"  #inform_prompt 앞부분에 concat\n",
    "        input_ids = tokenizer.encode(input_text, truncation=True ,max_length=3500, return_tensors='pt').to(device)\n",
    "        #print(f'INPUT_TEXT: {input_text}')\n",
    "        # 모델로부터 답변 생성\n",
    "        output_ids = model.generate(input_ids, max_length=3500)[0]\n",
    "        generated_answer = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "        #print(f'OUTPUT_TEXT: {generated_answer[3206:]}\\n')\n",
    "        #print(f'True OUTPUT: {output_data[i]}')\n",
    "        #print(f'True Ans: {output_data[i]}')\n",
    "        #true_positive, false_positive, false_negative 계산\n",
    "        #print(f'output_size: {output_size}')\n",
    "        gen_start_id = generated_answer[3206:].find(\"<<\") ## \"<<\"로 시작하는 곳과 \">>\"로 끝나는 곳을 찾은 후에 그 사이를 real_gen으로 저장해서 y_pred를 만들었어요.\n",
    "        gen_end_id = generated_answer[3206:].find(\">>\")\n",
    "        #print(f'Gen_ans: {generated_answer[(3206+gen_start_id):]}\\nstart: {gen_start_id}\\nend: {gen_end_id}')\n",
    "        real_gen = generated_answer[3208+gen_start_id:3206+gen_end_id].replace(\" \", \"\").replace(\">>\", \"\").split(\",\")\n",
    "        #print(f'Real_gen: {real_gen}')\n",
    "        y_pred.append(real_gen)\n",
    "    for i, real in enumerate(y_real):\n",
    "        #print(f'real_y: {real}')\n",
    "        #print(f'pred_y: {y_pred[i]}')\n",
    "        real_cnt = Counter(real) \n",
    "        pred_cnt = Counter(y_pred[i])\n",
    "        common = real_cnt & pred_cnt\n",
    "        tp += len(common.values())\n",
    "        if len(real) > len(y_pred[i]):\n",
    "            gap = len(real) - len(common.values())\n",
    "            fn += gap\n",
    "        elif len(real) < len(y_pred[i]):\n",
    "            gap = len(y_pred[i]) - len(common.values())\n",
    "            fp += gap\n",
    "        #print(f'tp: {tp}, fp: {fp}, fn: {fn}')\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision*recall/(precision+recall))\n",
    "\n",
    "    metric = [precision, recall, f1]\n",
    "    return metric\n",
    "\n",
    "# 테스트 데이터셋에 대한 모델 평가\n",
    "accuracy = evaluate(model, tokenizer, test_dataset)\n",
    "print(f'F1: {accuracy[2]}\\nPrecision: {accuracy[0]}\\nRecall: {accuracy[1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request F1, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "with open(\"request_test_data.json\", \"r\") as file:\n",
    "    test_dataset = json.load(file)\n",
    "\n",
    "\n",
    "# 모델을 평가하기 위한 함수\n",
    "def evaluate(model, tokenizer, dataset, device='cuda:3'):\n",
    "    y_pred = []\n",
    "    y_real = []\n",
    "    model.to(device)\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "    for text in dataset[\"input\"]:\n",
    "        input_data.append(text)\n",
    "    for text in dataset[\"output\"]:\n",
    "        output_data.append(text)\n",
    "    for text in output_data:\n",
    "        out = text.split(\",\")\n",
    "        y_real.append(out)\n",
    "    #print(y_real)\n",
    "    tp, fn, fp = 0, 0, 0\n",
    "    for i in tqdm(range(len(dataset['input']))):\n",
    "        # 입력 프롬프트 생성\n",
    "        input_text = f\"{request_correct_prompt_long}\\n{input_data[i]}\\n\"              #intent_prompt 앞부분에 concat\n",
    "        input_ids = tokenizer.encode(input_text, truncation=True ,max_length=5000, return_tensors='pt').to(device)\n",
    "        #print(f'INPUT_TEXT: {input_text}')\n",
    "        # 모델로부터 답변 생성\n",
    "        output_ids = model.generate(input_ids, max_length=7000)[0]\n",
    "        generated_answer = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "        #print(f'OUTPUT_TEXT: {generated_answer[4177:]}\\n')\n",
    "        #print(f'True OUTPUT: {output_data[i]}')\n",
    "        #print(f'True Ans: {output_data[i]}')\n",
    "        #true_positive, false_positive, false_negative 계산\n",
    "\n",
    "        #print(f'output_size: {output_size}') \n",
    "        if 'quest:' in generated_answer[4177:]: #### 1570번째 붙이는 이유: llama2는 input을 그대로 뱉고 output을 주더라고요. 앞에 input이 대략 1570자가 있다고 보시면 됩니다.\n",
    "            gen_start_id = generated_answer[4177:].find(\"est:\")\n",
    "        elif 'put:' in generated_answer[4177:]:\n",
    "            gen_start_id = generated_answer[4177:].find(\"put:\")\n",
    "        else:\n",
    "            gen_start_id = 10000\n",
    "        #print(generated_answer[1377+gen_start_id:])\n",
    "        \n",
    "        real_gen = generated_answer[4181+gen_start_id:] #strip 사용해야함! ## put: 이 4자라서 4를 더해서 1574입니다. \n",
    "        if ',' in real_gen:\n",
    "            real_gen = real_gen.replace(\"*\",\"\").replace(\" \",\"\").split(\",\")\n",
    "            for j in real_gen:\n",
    "                j = j.strip()\n",
    "            y_pred.append(real_gen)\n",
    "            #print(f'1: {real_gen}')\n",
    "        elif '*' in real_gen:\n",
    "            real_gen = real_gen.replace(\"\\n\",\"\").replace(\" \",\"\").split(\"*\")\n",
    "            y_pred.append(real_gen[1:])\n",
    "            #print(f'2: {real_gen[1:]}')\n",
    "        else:\n",
    "            y_pred.append([\"\"])\n",
    "        #print(f'real_gen: {real_gen}')\n",
    "    #print(len(y_pred))\n",
    "    #print(len(y_real))\n",
    "\n",
    "    for i, real in enumerate(y_real):\n",
    "        #print(f'real_y: {real}')\n",
    "        #print(f'pred_y: {y_pred[i]}')\n",
    "        real_cnt = Counter(real) \n",
    "        pred_cnt = Counter(y_pred[i])\n",
    "        common = real_cnt & pred_cnt\n",
    "        tp += len(common.values())\n",
    "        if len(real) > len(y_pred[i]):\n",
    "            gap = len(real) - len(common.values())\n",
    "            fn += gap\n",
    "        elif len(real) < len(y_pred[i]):\n",
    "            gap = len(y_pred[i]) - len(common.values())\n",
    "            fp += gap\n",
    "        print(f'tp: {tp}, fp: {fp}, fn: {fn}')\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision*recall/(precision+recall))\n",
    "\n",
    "    metric = [precision, recall, f1]\n",
    "    return metric\n",
    "\n",
    "# 테스트 데이터셋에 대한 모델 평가\n",
    "accuracy = evaluate(model, tokenizer, test_dataset)\n",
    "print(f'F1: {accuracy[2]}\\nPrecision: {accuracy[0]}\\nRecall: {accuracy[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inform Category Scale에 뭐뭐 있는지 확인...\n",
    "\n",
    "with open(\"inform_test_data.json\", \"r\") as file:\n",
    "    test_dataset = json.load(file)\n",
    "\n",
    "data = []\n",
    "basket = []\n",
    "for text in test_dataset[\"output\"]:\n",
    "    data.append(text)\n",
    "for i in data:\n",
    "    for j in i.split(\",\"):\n",
    "        basket.append(j)\n",
    "Counter(basket)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
